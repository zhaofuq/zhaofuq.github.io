<!DOCTYPE html>
<html lang="cx">

<head>
  <title>Fuqiang Zhao's Homepage - Shanghaitech University</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta charset="utf-8" />
  <meta name="keywords" content="" />
  <script>
    addEventListener("load", function () {
      setTimeout(hideURLbar, 0);
    }, false);

    function hideURLbar() {
      window.scrollTo(0, 1);
    }
  </script>
  <!-- Custom Theme files -->
  <link href="css/bootstrap.css" type="text/css" rel="stylesheet" media="all">
  <link href="css/style.css" type="text/css" rel="stylesheet" media="all">
  <!-- font-awesome icons -->
  <link href="css/fontawesome-all.min.css" rel="stylesheet">
  <!-- //Custom Theme files -->
  <!-- online-fonts -->
  <link href="http://fonts.googleapis.com/css?family=Source+Sans+Pro:200,300,400,600,700,900" rel="stylesheet">
  <!-- //online-fonts -->
  <style>
	#news-box {
	height: 75px;
	overflow: hidden;
}
#news-box-more{
	font-size: 14px;
}

  </style>
</head>

<body>
  <div class="sidenav">
    <div class="side_top"> <img src="images/zhaofq.jpg" width="75%" alt="news image" class="img-fluid navimg">
      <h1> Fuqiang Zhao - 赵富强 <br>
        [<a href="files/CV/CV_Zhao.pdf">Download CV</a> | <a href="https://www.linkedin.com/in/fuqiang-zhao-190227208/">LinkedIn</a>]<br>
        [<a href="mailto:zhaofq@shanghaitech.edu.cn">Email</a> | <a href="https://github.com/zhaofuq">GitHub</a> 
          | <a href="https://scholar.google.com/citations?user=_LoTgnIAAAAJ&hl=zh-CN&oi=ao">Scholar</a>]<br>
      </h1>
    </div>
    <!-- header -->
    <header>
      <div class="container-fluid px-5 ">
        <nav class="mnu mx-auto">
          <label for="drop" class="toggle">Menu</label>
          <input type="checkbox" id="drop">
          <ul class="menu">
            <!--<li><a href="index.html">Home</a></li-->
            <li class="mt-sm-0"><a href="#about" class="scroll">Bio</a></li>
            <li class="mt-sm-3"><a href="#publication" class="scroll">Publications</a></li>
            <li class="mt-sm-3"><a href="#experience" class="scroll">Experience</a></li>
            <li class="mt-sm-3"><a href="#skill" class="scroll">Skills</a></li>
          </ul>
        </nav>
      </div>
    </header>
  </div>
  <div class="main" id="about">
    <div class="banner-text-w3ls">
      <div>
        <div class="mx-auto text-left">
          <h1><strong>Fuqiang Zhao - 赵富强</strong></h1>
          <br> 
          <h5>Ph.D Candidate @ <a href="http://www.shanghaitech.edu.cn/"><b>ShanghaiTech University - 上海科技大学 </b></a> - <a
            href="http://sist.shanghaitech.edu.cn/">SIST</a> - <a
            href="http://vic.shanghaitech.edu.cn/">VDI</a></h5>
          <p><a href="mailto:zhaofq@shanghaitech.edu.cn">zhaofq@shanghaitech.edu.cn</a></p>
          <br>
          <h5><b>About Me</b></h5>
          Hi, now I am a PhD student in <strong>computer science and technology</strong> at VRVC Lab, <a
            href="http://www.shanghaitech.edu.cn/">ShanghaiTech University</a> ,advised by <a
            href="http://www.yu-jingyi.com/">Prof. Jingyi Yu</a>. I obtained my B.E. in <strong>software engineering </strong> at <a
            href="https://www.upc.edu.cn/">China University of Petroleum</a>.
         
            I am passionate and interested in <strong>reconstruction, rendering and generation</strong> tasks based on <strong>Neural Radiance Field</strong>. 
          </p>
          <li>Neural Rendering</li>
          <li>Text-To-3D & Image-To-3D Generation</li>
          <li>3D & 4D Reconstruction</li>
          <br>
          <h5><b>News!</b></h5>
          </p>
           <div id="news-box">
			<li>[2023.06]&ensp; I serve as ICCV 2023 reviewer, review 5 papers.</li>
			<li>[2022.12]&ensp; I serve as CVPR 2023 reviewer, review 3 papers.</li>
			<li>[2022.09]&ensp; Human Performance Modeling and Rendering via Neural Animated Mesh is accepted by SIGGRAPH Asia 2022.</li>
			<li>[2022.06]&ensp; I join NeuDim Digital Technology Inc, serve as CEO.</li>
			<li>[2022.05]&ensp; I serve as ECCV 2022 reviewer, review 3 papers.</li>
			<li>[2022.03]&ensp; HumanNeRF is accepted by CVPR 2022. Dataset is released.</li>
			<li>[2022.01]&ensp; I serve as CVPR 2022 reviewer, review 2 papers.</li>
		   </div>
		   <a id="news-box-more" href="javascript:;"style="font-size:16px;">MORE >></a>
        </div>
      </div>
    </div>

    <!-- publications -->
    <section class="wedo" id="publication">
      <div class="container-fluid py-lg-1">
        <h3 class="w3_head mb-5">Publications <font size ="5"></font></h3>
          <div class="row paper-box">
            <div class="col-md-3 col-12 paper_img"> 
              <img 
                src="files/Paper/nephele.png" width="100%" playsinline=""
                autoplay="autoplay" loop="loop" preload="" muted="" alt="Popup Image" class="img-fluid" />
              </div>
       
            <div class="col-md-9 col-12 paper-content">
              <h4>NEPHELE: A Neural Platform for Highly Realistic Cloud Radiance Rendering<br>
              </h4>
              <p>Haimin Luo, Siyuan Zhang, <strong>Fuqiang Zhao</strong>, Haotian Jing, Penghao Wang, Zhenxiao Yu, Dongxue Yan, Junran Ding, Boyuan Zhang, Qiang Hu, Shu Yin, Lan Xu, JIngyi Yu<br>
              </p>
              <p>(<strong>Arxiv 2023</strong>)</p>
              <p>
                [ProjectPage</a>]
                [<a href="https://arxiv.org/pdf/2303.04086.pdf">ArxivPage</a>]
              </p>
            </div>
       
          </div>


          <div class="row paper-box">
            <div class="col-md-3 col-12 paper_img"> 
              <img 
                src="files/Paper/HPRAM.jpg" width="90%" playsinline=""
                autoplay="autoplay" loop="loop" preload="" muted="" alt="Popup Image" class="img-fluid" />
              </div>
            <!-- .Icon ends here -->
            <div class="col-md-9 col-12 paper-content">
              <h4>Human Performance Modeling and Rendering via Neural Animated Mesh<br>
              </h4>
              <p><strong>Fuqiang Zhao</strong>, Yuheng Jiang, Kaixin Yao, Jiakai Zhang, Liao Wang, Haizhao Dai, Yuhui Zhong, Yingliang Zhang, Minye Wu, Lan Xu, Jingyi Yu<br>
              </p>
              <p>(<strong>SIGGRAPH Aisa 2022</strong>)</p>
              <p>
                [<a href="https://zhaofuq.github.io/NeuralAM/">ProjectPage</a>]
                [<a href="https://arxiv.org/pdf/2209.08468.pdf">ArxivPage</a>]
                [<a href="https://github.com/zhaofuq/Instant-NSR">Code1</a>]
                [<a href="https://github.com/nowheretrix/Instant-NK">Code2</a>] 
              </p>
            </div>
            <!-- .Service-content ends here -->
          </div>


          <div class="row paper-box">
            <div class="col-md-3 col-12 paper_img"> 
              <img 
                src="files/Paper/neuvv.png" width="90%" playsinline=""
                autoplay="autoplay" loop="loop" preload="" muted="" alt="Popup Image" class="img-fluid" />
              </div>
            <!-- .Icon ends here -->
            <div class="col-md-9 col-12 paper-content">
              <h4>NeuVV: Neural Volumetric Videos with Immersive Rendering and Editing<br>
              </h4>
              <p>Jiakai Zhang, Liao Wang, Xinhang Liu, <strong>Fuqiang Zhao</strong>, Minzhang Li, Haizhao Dai, Boyuan Zhang, Wei Yang, Lan Xu, Jingyi Yu<br>
              </p>
              <p>(<strong>Arxiv 2022</strong>)Preprint</p>
              <p>
                [ProjectPage</a>]
                [<a href="https://arxiv.org/pdf/2202.06088.pdf">ArxivPage</a>]
              </p>
            </div>
            <!-- .Service-content ends here -->
          </div>

          <div class="row paper-box">
            <div class="col-md-3 col-12 paper_img"> 
              <img 
                src="files/Paper/fpo.png" width="90%" playsinline=""
                autoplay="autoplay" loop="loop" preload="" muted="" alt="Popup Image" class="img-fluid" />
              </div>
            <!-- .Icon ends here -->
            <div class="col-md-9 col-12 paper-content">
              <h4>Fourier PlenOctrees for Dynamic Radiance Field Rendering in Real-time<br>
              </h4>
              <p>Liao Wang*, Jiakai Zhang*, Xinhang Liu, <strong>Fuqiang Zhao</strong>, Yanshun Zhang, Yingliang Zhang, Minye Wu Lan Xu, Jingyi Yu<br>
              </p>
              <p>(<strong>CVPR 2022 Oral</strong>)Conference on Computer Vision and Pattern Recognition</p>
              <p>[<a href="https://aoliao12138.github.io/FPO/">ProjectPage</a>] 
                [<a href="https://arxiv.org/abs/2202.08614">ArxivPage</a>]

                [<a href="https://aoliao12138.github.io/FPO/">Code</a>] 
              </p>
            </div>
            <!-- .Service-content ends here -->
          </div>

          <div class="row paper-box">
            <div class="col-md-3 col-12 paper_img"> 
              <img 
                src="files/Paper/humannerf.png" width="90%" playsinline=""
                autoplay="autoplay" loop="loop" preload="" muted="" alt="Popup Image" class="img-fluid" />
              </div>
            <!-- .Icon ends here -->
            <div class="col-md-9 col-12 paper-content">
              <h4><strong>HumanNeRF</strong>: Efficiently Generated Human Radiance Field from Sparse Inputs<br>
              </h4>
              <p><strong>Fuqiang Zhao</strong>, Wei Yang, Jiakai Zhang, Pei Lin, Yingliang Zhang, Jingyi Yu, Lan Xu<br>
              </p>
              <p>(<strong>CVPR 2022</strong>)Conference on Computer Vision and Pattern Recognition</p>
              <p>[<a href="https://zhaofuq.github.io/humannerf/">ProjectPage</a>] 
                [<a href="https://arxiv.org/pdf/2112.02789.pdf">ArxivPage</a>]
                [<a href="https://zhaofuq.github.io/humannerf/">Code</a>]

              </p>
            </div>
            <!-- .Service-content ends here -->
          </div>
          <div class="row paper-box">
            <div class="col-md-3 col-12 paper_img"> 
              <img 
                src="files/Paper/mvsnerf.png" width="90%" playsinline=""
                autoplay="autoplay" loop="loop" preload="" muted="" alt="Popup Image" class="img-fluid" />
              </div>
            <!-- .Icon ends here -->
            <div class="col-md-9 col-12 paper-content">
              <h4><strong>MVSNeRF</strong>: Fast Generalizable Radiance Field Reconstruction from Multi-View Stereo<br>
              </h4>
              <p>Anpei Chen, Zexiang Xu, <strong>Fuqiang Zhao</strong>, Xiaoshuai Zhang, Fanbo Xiang, Jingyi Yu, Hao Su<br>
              </p>
              <p>(<strong> ICCV 2021</strong>) International Conference on Computer Vision</p>
              <p>[<a href="https://apchenstu.github.io/mvsnerf/">ProjectPage</a>]  
                [<a href="https://arxiv.org/abs/2103.15595">ArxivPage</a>] 
                [<a href="https://github.com/apchenstu/mvsnerf">Code</a>]
              </p>
            </div>
            <!-- .Service-content ends here -->
          </div>
          <div class="row paper-box">
            <div class="col-md-3 col-12 paper_img"> 
                  <img 
                    src="files/Paper/editable.png" width="90%" playsinline=""
                    autoplay="autoplay" loop="loop" preload="" muted="" alt="Popup Image" class="img-fluid" />
                  </div>
                <!-- .Icon ends here -->
                <div class="col-md-9 col-12 paper-content">
                  <h4>Editable Free-Viewpoint Video using a Layered Neural Representation</h4>
                  <p>Jiakai Zhang, Xinhang Liu, Xinyi Ye, <strong>Fuqiang Zhao</strong>, Yanshun Zhang, Minye Wu, Yingliang Zhang, Lan Xu and Jingyi Yu</p>
                  <p>(<strong>SIGGRAPH 2021</strong>) ACM Transactions on Graphics(Proce. of ACM SIGGRAPH 2021)</p>
                  <p>[<a href="https://jiakai-zhang.github.io/st-nerf/">ProjectPage</a>]  
                    [<a href="https://arxiv.org/pdf/2104.14786.pdf">ArxivPage</a>] 
                    [<a href="https://github.com/DarlingHang/st-nerf">Code</a>]
                    [<a href="https://www.youtube.com/watch?v=UrB-tqA8oeg&t=2s">Two Minute Papers</a>]
                    [<a href="https://www.youtube.com/watch?v=UrB-tqA8oeg&t=2s">Interview with German National Audio</a>]
                  </p>
                </div>
            </div>              
          <div class="row paper-box">
            <div class="col-md-3 col-12 paper_img"> 
              <img 
                src="files/Paper/mirrornerf.png" width="90%" playsinline=""
                autoplay="autoplay" loop="loop" preload="" muted="" alt="Popup Image" class="img-fluid" />
              </div>
            <!-- .Icon ends here -->
            <div class="col-md-9 col-12 paper-content">
              <h4><strong>MirrorNeRF</strong>: One-shot Neural Portrait Radiance Field from Multi-mirror Catadioptric Imaging<br>
              </h4>
              <p>Ziyu Wang, Liao Wang, <strong>Fuqiang Zhao</strong>, Minye Wu, Lan Xu, Jingyi Yu<br>
              </p>
              <p>(<strong> ICCP 2021</strong>) International Conference on Computational Photography</p>
            
              <p>[ProjectPage] 
                [<a href="https://arxiv.org/pdf/2104.02607.pdf">ArxivPage</a>]
              </p>
            </div>
            <!-- .Service-content ends here -->
          </div>
    </section>



    <!-- experience -->
    <section class="wedo" id="experience">
      <div class="experience">
        <h3 class="w3_head mb-5">Experience</h3>
        <div class="row service_w3top mt-5">
          <div class="col-xl-12">
            <div class="d-flex experience-box">
              <div class="icon"><span class="fa fa-briefcase"></span> </div>
              <!-- .Icon ends here -->
              <div class="service-content">
                <div class="d-md-flex justify-content-between">
                  <h4><a href="http://neudim.com/">NeuDim Digital Technology Inc. - 上海赜深数字科技有限公司</a></h4>
                  <h4> July. 2022 - Present</h4>
                </div>
                <h4> CEO&amp;Founder</h4>
                <p>NeuDim aims to substitute classical photogrammetry-based 3D/4D reconstruction 
                    with emerging neural approaches. It was incubated from the Visual Data Intelligence (VDI) Center at ShanghaiTech, 
                    by a group of fearless PhD students with various expertise on neural modeling, rendering, and tracking.</a></p>
                <br>
              </div>
              <!-- .Service-content ends here -->
            </div>
            <div class="d-flex experience-box">
              <div class="icon"><span class="fa fa-briefcase"></span> </div>
              <!-- .Icon ends here -->
              <div class="service-content">
                <div class="d-md-flex justify-content-between">
                  <h4><a href="https://www.dgene.com/cn/">DGene Digital Technology Inc. - 上海叠境数字科技有限公司</a></h4>
                  <h4> Jan. 2022 - Sep. 2022</h4>
                </div>
                <h4> R&amp;D Intern</h4>
                <p>I work as a part-time research and development intern at <a href="https://www.dgene.com/eng/">DGene
                    Digital Technology Inc. </a></p>
                <br>
              </div>
              <!-- .Service-content ends here -->
            </div>
          </div>
        </div>
        <h3 class="w3_head mb-5">Education</h3>
        <div class="row service_w3top mt-5">
          <div class="col-xl-12">
            <div class="d-flex experience-box">
              <div class="icon"> <span class="fa fa-graduation-cap"></span> </div>
              <!-- .Icon ends here -->
              <div class="service-content">
                <div class="d-md-flex justify-content-between">
                  <h4><a href="http://www.shanghaitech.edu.cn/eng/">ShanghaiTech University - 上海科技大学</a></h4>
                  <h4>Sep. 2020 - Present </h4>
                </div>
                <h4> Ph.D Candidate</h4>
                <p>I now am a Ph.D candidate on computer vision research, advised by <a href="http://www.yu-jingyi.com/">Prof. Jingyi Yu</a> 
                  and developed a light-weight framework for rendering 3D dynamic humans from a six RGB cameras.</p>
                <br>
              </div>
              <!-- .Service-content ends here -->
            </div>
            <div class="d-flex experience-box">
              <div class="icon"> <span class="fa fa-graduation-cap"></span> </div>
              <!-- .Icon ends here -->
              <div class="service-content">
                <div class="d-md-flex justify-content-between">
                  <h4><a href="http://english.upc.edu.cn/">China University of Petroleum - 中国石油大学(华东)</a></h4>
                  <h4>Sep. 2016 - Jul. 2020 </h4>
                </div>
                <h4> Bachelor </h4>
                <p>I obtained my B.E. in software engineering at China University of Petroleum and won honorable awards
                  including: </p>
                <li>Outstanding Graduates of China University of Petroleum 2020</li>
                <li>First Prize of Shandong Software Design Competition 2018</li>
                <li>National Inspirational Scholarship 2017,2018</li>
                <li>Merit Student 2017,2018</li>
              </div>
              <!-- .Service-content ends here -->
            </div>
          </div>
        </div>
      </div>
    </section>

        <!-- Supervisors -->
    <section class="wedo" id="-Supervisors">
      <h3 class="w3_head col-md-12 mb-12"> Supervisors </h3>
      <div id="id4" style="clear:both"></div>
      <div class="col-md-5 col-12 people-content">
        <p class="banp mt-5"> <a href="http://www.yu-jingyi.com/">Prof. Jingyi Yu</a> - Supervisor </p>
        <li>Executive Dean, SIST, ShanghaiTech University</li>
        <li>Ph.D.'s degree, MIT, 2005</li>
      </div>
      <div id="id4" style="clear:both"></div>
    </section>

    <!-- //skill -->
    <section class="wedo" id="skill">
      <h3 class="w3_head mb-1">Skills </h3>
      <p class="banp mt-5"> Programming Languages</p>
      <ul class="fa-ul mb-0">
        <li> <i class="fa-li fa fa-check"></i> C++, CUDA and so on. </li>
        <li> <i class="fa-li fa fa-check"></i> Python (Pytorch and so on.)</li>
        <li> <i class="fa-li fa fa-check"></i> WebGL, javascript and so on.</li>
      </ul>
      <p class="banp mt-5"> Others</p>
      <ul class="fa-ul mb-0">
        <li> <i class="fa-li fa fa-check"></i> Latex, Markdown</li>

      </ul>
    </section>
    <!-- //skill -->
  </div>
  <script>
	var newsBoxMoreBtn = document.getElementById('news-box-more')
	var newsBox = document.getElementById('news-box');
	var flag = false;
	newsBoxMoreBtn.addEventListener('click',function(){
		flag = !flag;
		if(flag){
			newsBox.style.height = 'auto';
			newsBoxMoreBtn.innerHTML = 'CLOSE <<'
		}
		else{
			newsBox.style.height = '75px';
			newsBoxMoreBtn.innerHTML = 'MORE >>'
		}
		
	})
  </script>
</body>

</html>